## Binary classiffication with logistic regression with Apache Spark Pipelines

# The dataset contains 9568 data points collected from a Combined 
# Cycle Power Plant over 6 years (2006-2011), when the power plant 
# was set to work with full load. Features consist of hourly average 
# ambient variables Temperature (AT), Ambient Pressure (AP), Relative 
# Humidity (RH) and Exhaust Vacuum (V) to predict the net hourly 
# electrical energy output (PE)  of the plant. A combined cycle  
# power plant (CCPP) is composed of gas turbines (GT), steam turbines (ST)  
# and heat recovery steam generators. In a CCPP, the electricity is  
# generated by gas and steam turbines, which are combined in one cycle,  
# and is transferred from one turbine to another. While the Vacuum is  
# colected from and has effect on the Steam Turbine, he other three of  
# the ambient variables effect the GT performance.

library(sparklyr)
library(dplyr)

# link to local spark cluster
sc <- spark_connect(master = "local")

# copy data to spark cluster
spark_powerplant <- spark_read_csv(sc, 
                                   name = "spark_powerplant", 
                                   path = "C:/PowePlantProject/powerplant.csv", 
                                   header = TRUE, 
                                   delimiter = ",")

# check mean power output value for easy binarization
tbl(sc, "spark_powerplant") %>% 
  summarize(
    mean_PE = mean(PE, na.rm = TRUE)
  )

# 454


# transformer
df <- spark_powerplant %>%
        rename(ambient_temp = AT,
               vacuum = V,
               ambient_presure = AP,
               rel_humidity = RH,
               energy_output = PE) %>%
        filter(!is.na(ambient_temp),
               !is.na(vacuum),
               !is.na(ambient_presure),
               !is.na(rel_humidity),
               !is.na(energy_output)) %>%
        select(ambient_temp, 
               vacuum, 
               ambient_presure, 
               rel_humidity, 
               energy_output)

# create transformer pipeline stage
ft_dplyr_transformer(sc, df)

# check transformer internal sql intruction
ft_dplyr_transformer(sc, df) %>%
  ml_param("statement")

## create the pipeline
#The following step will create a 5 stage pipeline:

#SQL transformer - Resulting from the ft_dplyr_transformer() transformation
#Binarizer - To determine if the energy output should be considered high or low. The eventual outcome variable.
#R Formula - To define the model's formula
#Logistic Model

powerplant_pipeline <- ml_pipeline(sc) %>%
  ft_dplyr_transformer(
    tbl = df
  ) %>%
  ft_binarizer(
    input_col = "energy_output",
    output_col = "energy_lvl",
    threshold = 454
  ) %>%
  ft_r_formula(energy_lvl ~ ambient_temp + vacuum + ambient_presure + rel_humidity) %>% 
  ml_logistic_regression()

# print pipeline
powerplant_pipeline


## fit the pipeline
# partition data
partitioned_powerplant <- sdf_partition(
  spark_powerplant,
  training = 0.7,
  testing = 0.3
)

# fit and print
fitted_pipeline <- ml_fit(
  powerplant_pipeline,
  partitioned_powerplant$training
)
fitted_pipeline

## test pipeline
# make predictions
predictions <- ml_transform(
  fitted_pipeline,
  partitioned_powerplant$testing
)

# show results confussion matrix
predictions %>%
  group_by(energy_lvl, prediction) %>%
  tally()

# A tibble: 4 x 3
# energy_lvl prediction     n
# *      <dbl>      <dbl> <dbl>
# 1          0          1    66
# 2          1          1  1282
# 3          1          0    60
# 4          0          0  1452

# great outcome!

# save "empty" pipeline
ml_save(
  powerplant_pipeline,
  "powerplant_pipeline",
  overwrite = TRUE
)

# save the fitted pipeline
ml_save(
  fitted_pipeline,
  "powerplant_fitted_model",
  overwrite = TRUE
)

# The resulting output is a folder with the selected name, which contains all of the necessary Scala scripts.

## Using an existing pipeline
# Load fitted pipeline into the spark cluster
reloaded_model <- ml_load(sc, "powerplant_fitted_model")

new_df <- spark_powerplant %>%
  filter(
    PE < 480
  )

ml_transform(reloaded_model, new_df)

## refit an existing pipeline
# load the pipeline
reloaded_pipeline <- ml_load(sc, "powerplant_pipeline")

# refit the model
new_model <-  ml_fit(reloaded_pipeline, sample_frac(spark_powerplant, 0.8))

# print the new model
new_model

## save the new model
ml_save(new_model, "new_powerplant_model", overwrite = TRUE)

## close spark cluster connection
spark_disconnect(sc)


## References:

# Pinar Tüfekci, Prediction of full load electrical power output 
# of a base load operated combined cycle power plant using machine
# learning methods, International Journal of Electrical Power & 
# Energy Systems, Volume 60, September 2014, Pages 126-140, ISSN 
# 0142-0615, http://dx.doi.org/10.1016/j.ijepes.2014.02.027. 
# (http://www.sciencedirect.com/science/article/pii/S0142061514000908)

# Heysem Kaya, Pinar Tüfekci , Sadik Fikret Gürgen: Local and Global
# Learning Methods for Predicting Power of a Combined Gas & Steam 
# Turbine, Proceedings of the International Conference on Emerging 
# Trends in Computer and Electronics Engineering ICETCEE 2012, pp. 
# 13-18 (Mar. 2012, Dubai)
