{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with LSTM Deep Neural Networks\n",
    "\n",
    "The following model aims to predict wether an amazon review is positive or negative. The product reviews are from the Electronics section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the required packages are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import keras as ks\n",
    "from matplotlib import pyplot\n",
    "import gzip \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the data is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path): \n",
    "    g = gzip.open(path, 'rb') \n",
    "    for l in g: \n",
    "        yield eval(l) \n",
    "def getDF(path): \n",
    "    i = 0 \n",
    "    df = {} \n",
    "    for d in parse(path): \n",
    "        df[i] = d \n",
    "        i += 1 \n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "df = getDF('reviews_Electronics_5.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AO94DHGC771SJ</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>amazdnu</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Gotta have GPS!</td>\n",
       "      <td>1370131200</td>\n",
       "      <td>06 2, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMO214LNFCEI4</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[12, 15]</td>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Very Disappointed</td>\n",
       "      <td>1290643200</td>\n",
       "      <td>11 25, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3N7T0DY83Y4IG</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>C. A. Freeman</td>\n",
       "      <td>[43, 45]</td>\n",
       "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1st impression</td>\n",
       "      <td>1283990400</td>\n",
       "      <td>09 9, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1H8PY3QHMQQA0</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Dave M. Shaw \"mack dave\"</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>Not going to write a long review, even thought...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Great grafics, POOR GPS</td>\n",
       "      <td>1290556800</td>\n",
       "      <td>11 24, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A24EV6RXELQZ63</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Wayne Smith</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I've had mine for a year and here's what we go...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Major issues, only excuses for support</td>\n",
       "      <td>1317254400</td>\n",
       "      <td>09 29, 2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin              reviewerName   helpful  \\\n",
       "0   AO94DHGC771SJ  0528881469                   amazdnu    [0, 0]   \n",
       "1   AMO214LNFCEI4  0528881469           Amazon Customer  [12, 15]   \n",
       "2  A3N7T0DY83Y4IG  0528881469             C. A. Freeman  [43, 45]   \n",
       "3  A1H8PY3QHMQQA0  0528881469  Dave M. Shaw \"mack dave\"   [9, 10]   \n",
       "4  A24EV6RXELQZ63  0528881469               Wayne Smith    [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  We got this GPS for my husband who is an (OTR)...      5.0   \n",
       "1  I'm a professional OTR truck driver, and I bou...      1.0   \n",
       "2  Well, what can I say.  I've had this unit in m...      3.0   \n",
       "3  Not going to write a long review, even thought...      2.0   \n",
       "4  I've had mine for a year and here's what we go...      1.0   \n",
       "\n",
       "                                  summary  unixReviewTime   reviewTime  \n",
       "0                         Gotta have GPS!      1370131200   06 2, 2013  \n",
       "1                       Very Disappointed      1290643200  11 25, 2010  \n",
       "2                          1st impression      1283990400   09 9, 2010  \n",
       "3                 Great grafics, POOR GPS      1290556800  11 24, 2010  \n",
       "4  Major issues, only excuses for support      1317254400  09 29, 2011  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable will be based on the overall rating column, therefore, samples with that missing variable are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['overall'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to label as positive review those with rating above 3 and as negative those below 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['overall']!=3.0]\n",
    "df.loc[df['overall']>3.0, 'sent'] = 1\n",
    "df.loc[df['overall']<3.0, 'sent'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary and reviewText are concatenated such that there is only one input for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['summary'] + '. ' + df['reviewText']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check again the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>sent</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AO94DHGC771SJ</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>amazdnu</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Gotta have GPS!</td>\n",
       "      <td>1370131200</td>\n",
       "      <td>06 2, 2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Gotta have GPS!. We got this GPS for my husban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMO214LNFCEI4</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[12, 15]</td>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Very Disappointed</td>\n",
       "      <td>1290643200</td>\n",
       "      <td>11 25, 2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Very Disappointed. I'm a professional OTR truc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1H8PY3QHMQQA0</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Dave M. Shaw \"mack dave\"</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>Not going to write a long review, even thought...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Great grafics, POOR GPS</td>\n",
       "      <td>1290556800</td>\n",
       "      <td>11 24, 2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Great grafics, POOR GPS. Not going to write a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A24EV6RXELQZ63</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Wayne Smith</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I've had mine for a year and here's what we go...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Major issues, only excuses for support</td>\n",
       "      <td>1317254400</td>\n",
       "      <td>09 29, 2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Major issues, only excuses for support. I've h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A2JXAZZI9PHK9Z</td>\n",
       "      <td>0594451647</td>\n",
       "      <td>Billy G. Noland \"Bill Noland\"</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>I am using this with a Nook HD+. It works as d...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>HDMI Nook adapter cable</td>\n",
       "      <td>1388707200</td>\n",
       "      <td>01 3, 2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HDMI Nook adapter cable. I am using this with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                   reviewerName   helpful  \\\n",
       "0   AO94DHGC771SJ  0528881469                        amazdnu    [0, 0]   \n",
       "1   AMO214LNFCEI4  0528881469                Amazon Customer  [12, 15]   \n",
       "3  A1H8PY3QHMQQA0  0528881469       Dave M. Shaw \"mack dave\"   [9, 10]   \n",
       "4  A24EV6RXELQZ63  0528881469                    Wayne Smith    [0, 0]   \n",
       "5  A2JXAZZI9PHK9Z  0594451647  Billy G. Noland \"Bill Noland\"    [3, 3]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  We got this GPS for my husband who is an (OTR)...      5.0   \n",
       "1  I'm a professional OTR truck driver, and I bou...      1.0   \n",
       "3  Not going to write a long review, even thought...      2.0   \n",
       "4  I've had mine for a year and here's what we go...      1.0   \n",
       "5  I am using this with a Nook HD+. It works as d...      5.0   \n",
       "\n",
       "                                  summary  unixReviewTime   reviewTime  sent  \\\n",
       "0                         Gotta have GPS!      1370131200   06 2, 2013   1.0   \n",
       "1                       Very Disappointed      1290643200  11 25, 2010   0.0   \n",
       "3                 Great grafics, POOR GPS      1290556800  11 24, 2010   0.0   \n",
       "4  Major issues, only excuses for support      1317254400  09 29, 2011   0.0   \n",
       "5                 HDMI Nook adapter cable      1388707200   01 3, 2014   1.0   \n",
       "\n",
       "                                              review  \n",
       "0  Gotta have GPS!. We got this GPS for my husban...  \n",
       "1  Very Disappointed. I'm a professional OTR truc...  \n",
       "3  Great grafics, POOR GPS. Not going to write a ...  \n",
       "4  Major issues, only excuses for support. I've h...  \n",
       "5  HDMI Nook adapter cable. I am using this with ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gotta have GPS!. We got this GPS for my husband who is an (OTR) over the road trucker.  Very Impressed with the shipping time, it arrived a few days earlier than expected...  within a week of use however it started freezing up... could of just been a glitch in that unit.  Worked great when it worked!  Will work great for the normal person as well but does have the \"trucker\" option. (the big truck routes - tells you when a scale is coming up ect...)  Love the bigger screen, the ease of use, the ease of putting addresses into memory.  Nothing really bad to say about the unit with the exception of it freezing which is probably one in a million and that\\'s just my luck.  I contacted the seller and within minutes of my email I received a email back with instructions for an exchange! VERY impressed all the way around!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the variables that are not of interest are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['review','sent']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we split into train and test dataset at 80/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what is the balance between postive and negative classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1084984\n",
       "0.0     152560\n",
       "Name: sent, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sent.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this is and unbalanced dataset. As the computing resources are limited and the amount of data large enough, we are going to randomly drop a number of postive cases until the dataset is balanced. That will help with common class inbalance issues and help with the undestanding of accuracy measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "0.0    152560\n",
      "1.0    152560\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Class count\n",
    "count_class_0 = (train['sent'] == 0).sum()\n",
    "count_class_1 = (train['sent'] == 1).sum()\n",
    "\n",
    "# Divide by class\n",
    "df_class_0 = train[train['sent'] == 0]\n",
    "df_class_1 = train[train['sent'] == 1]\n",
    "df_class_1_under = df_class_1.sample(count_class_0)\n",
    "train = pd.concat([df_class_1_under, df_class_0], axis=0)\n",
    "print('Random under-sampling:')\n",
    "print(train.sent.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "0.0    38304\n",
      "1.0    38304\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Class count\n",
    "count_class_0 = (test['sent'] == 0).sum()\n",
    "count_class_1 = (test['sent'] == 1).sum()\n",
    "\n",
    "# Divide by class\n",
    "df_class_0 = test[test['sent'] == 0]\n",
    "df_class_1 = test[test['sent'] == 1]\n",
    "df_class_1_under = df_class_1.sample(count_class_0)\n",
    "test = pd.concat([df_class_1_under, df_class_0], axis=0)\n",
    "print('Random under-sampling:')\n",
    "print(test.sent.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we expand the contractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['review'] = train['review'].apply(contractions.fix)\n",
    "test['review'] = test['review'].apply(contractions.fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not easy to use many leys and touchpad, connection is good. Additional buttons to be pressed which are single / dedicated in normal keyboard. touch pad not comfortable including left / right click buttons. Connection is good - set it and forget.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['review'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. Now we will tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['review'] = train['review'].apply(nltk.word_tokenize)\n",
    "test['review'] = test['review'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Not',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'use',\n",
       " 'many',\n",
       " 'leys',\n",
       " 'and',\n",
       " 'touchpad',\n",
       " ',',\n",
       " 'connection',\n",
       " 'is',\n",
       " 'good',\n",
       " '.',\n",
       " 'Additional',\n",
       " 'buttons',\n",
       " 'to',\n",
       " 'be',\n",
       " 'pressed',\n",
       " 'which',\n",
       " 'are',\n",
       " 'single',\n",
       " '/',\n",
       " 'dedicated',\n",
       " 'in',\n",
       " 'normal',\n",
       " 'keyboard',\n",
       " '.',\n",
       " 'touch',\n",
       " 'pad',\n",
       " 'not',\n",
       " 'comfortable',\n",
       " 'including',\n",
       " 'left',\n",
       " '/',\n",
       " 'right',\n",
       " 'click',\n",
       " 'buttons',\n",
       " '.',\n",
       " 'Connection',\n",
       " 'is',\n",
       " 'good',\n",
       " '-',\n",
       " 'set',\n",
       " 'it',\n",
       " 'and',\n",
       " 'forget',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['review'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to do a set of transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "train['review'] = train['review'].apply(normalize)\n",
    "test['review'] = test['review'].apply(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the number of unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407534"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['review'].apply(pd.Series).stack().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the number of words in each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 64.17 words STD(82.198017)\n"
     ]
    }
   ],
   "source": [
    "train['totalwords'] = train['review'].str.len().copy()\n",
    "print(\"Mean %.2f words STD(%f)\" % (np.mean(train['totalwords']), np.std(train['totalwords'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.boxplot(train['totalwords'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop the 10% most extreme samples in terms of number of words such that we have a better look at the number of words in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['totalwords']>train['totalwords'].quantile(0.05)]\n",
    "train = train[train['totalwords']<train['totalwords'].quantile(0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.boxplot(train['totalwords'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check if the dataset is still balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    138626\n",
      "1.0    136365\n",
      "Name: sent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.sent.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Lets finally resent the indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sent</th>\n",
       "      <th>totalwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[great, product, great, people, square, years,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[work, card, work, windows, 7, x64, machine, c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[oh, gosh, literally, crumbled, hand, got, use...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[minty, deliciousness, made, macbook, look, go...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[works, well, charger, works, daughter, kindle...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sent  totalwords\n",
       "0  [great, product, great, people, square, years,...   1.0          52\n",
       "1  [work, card, work, windows, 7, x64, machine, c...   0.0          71\n",
       "2  [oh, gosh, literally, crumbled, hand, got, use...   0.0          49\n",
       "3  [minty, deliciousness, made, macbook, look, go...   1.0          14\n",
       "4  [works, well, charger, works, daughter, kindle...   1.0          15"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to detokenize now such that we can take advantage of Keras tokenizer later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "train['review'] = train['review'].apply(TreebankWordDetokenizer().detokenize)\n",
    "test['review'] = test['review'].apply(TreebankWordDetokenizer().detokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will tokenize now with Keras tokenizer and use the top 5000 most common words for word sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequence\n",
    "top_words = 5000\n",
    "t = Tokenizer(num_words= top_words)\n",
    "t.fit_on_texts(train['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad dataset to a maximum review length in words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ... 3618 2147  595]\n",
      " [   0    0    0 ...   51   29  515]\n",
      " [   0    0    0 ...   93    6    1]\n",
      " ...\n",
      " [   0    0    0 ...  559 1860  265]\n",
      " [   0    0    0 ...  461  462  409]\n",
      " [   0    0    0 ...  836   75  111]]\n"
     ]
    }
   ],
   "source": [
    "max_words = 150\n",
    "sequences_train = t.texts_to_sequences(train['review'])\n",
    "X_train = ks.preprocessing.sequence.pad_sequences(sequences_train, maxlen=max_words)\n",
    "sequences_test = t.texts_to_sequences(test['review'])\n",
    "X_test = ks.preprocessing.sequence.pad_sequences(sequences_test, maxlen=max_words)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the LSTM neural network with dropout layers to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 32)           160000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 150, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 150)               109800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 151       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 269,951\n",
      "Trainable params: 269,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_length = 32 \n",
    "model = Sequential() \n",
    "model.add(Embedding(top_words, \n",
    "                    embedding_vector_length, \n",
    "                    input_length=max_words)) \n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=150,\n",
    "               activation='tanh',\n",
    "               recurrent_activation='hard_sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 269951 parameters to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 274991 samples, validate on 76608 samples\n",
      "Epoch 1/10\n",
      "274991/274991 [==============================] - 2443s 9ms/step - loss: 0.2743 - acc: 0.8871 - val_loss: 0.2368 - val_acc: 0.9065\n",
      "Epoch 2/10\n",
      "274991/274991 [==============================] - 2082s 8ms/step - loss: 0.2199 - acc: 0.9128 - val_loss: 0.2191 - val_acc: 0.9132\n",
      "Epoch 3/10\n",
      "274991/274991 [==============================] - 2079s 8ms/step - loss: 0.2073 - acc: 0.9177 - val_loss: 0.2147 - val_acc: 0.9143\n",
      "Epoch 4/10\n",
      "274991/274991 [==============================] - 2093s 8ms/step - loss: 0.1994 - acc: 0.9204 - val_loss: 0.2092 - val_acc: 0.9158\n",
      "Epoch 5/10\n",
      "274991/274991 [==============================] - 2147s 8ms/step - loss: 0.1931 - acc: 0.9234 - val_loss: 0.2086 - val_acc: 0.9169\n",
      "Epoch 6/10\n",
      "274991/274991 [==============================] - 2155s 8ms/step - loss: 0.1877 - acc: 0.9256 - val_loss: 0.2066 - val_acc: 0.9172\n",
      "Epoch 7/10\n",
      "274991/274991 [==============================] - 2112s 8ms/step - loss: 0.1824 - acc: 0.9276 - val_loss: 0.2039 - val_acc: 0.9187\n",
      "Epoch 8/10\n",
      "274991/274991 [==============================] - 2114s 8ms/step - loss: 0.1792 - acc: 0.9292 - val_loss: 0.2122 - val_acc: 0.9180\n",
      "Epoch 9/10\n",
      "274991/274991 [==============================] - 2091s 8ms/step - loss: 0.1752 - acc: 0.9309 - val_loss: 0.2057 - val_acc: 0.9183\n",
      "Epoch 10/10\n",
      "274991/274991 [==============================] - 2114s 8ms/step - loss: 0.1715 - acc: 0.9324 - val_loss: 0.1998 - val_acc: 0.9208\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, \n",
    "          train.sent, \n",
    "          validation_data=(X_test, test.sent), \n",
    "          epochs=10, \n",
    "          batch_size=128,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models is trained and we have achieved a 92% accuracy in the validation dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source citation:\n",
    "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering\n",
    "R. He, J. McAuley\n",
    "WWW, 2016"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 193.85,
   "position": {
    "height": "40px",
    "left": "568px",
    "right": "30px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
